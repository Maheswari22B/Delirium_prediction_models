{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction for Prediction task in time and last version of data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals.joblib import dump, load\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "eicu_path = \"the directory that indludes eicu csv files\"\n",
    "root_path = \"the directory that includes the main csv data\"\n",
    "data_processed_path = \"directory to load the extracted data\"\n",
    "def dataframe_from_csv(path, header=0, index_col=False):\n",
    "    return pd.read_csv(path, header=header, index_col=index_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = dataframe_from_csv(os.path.join(eicu_path, 'patient.csv'),index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Non-time series preprocessing\n",
    "###############################\n",
    "g_map = {'Female': 1, 'Male': 2, '': 0, 'NaN': 0, 'Unknown': 0, 'Other': 0}\n",
    "def transform_gender(gender_series):\n",
    "    global g_map\n",
    "    return {'gender': gender_series.fillna('').apply(lambda s: g_map[s] if s in g_map else g_map[''])}\n",
    "e_map = {'Asian': 1, 'African American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'NaN': 0, '': 0}\n",
    "def transform_ethnicity(ethnicity_series):\n",
    "    global e_map\n",
    "    return {'ethnicity': ethnicity_series.fillna('').apply(lambda s: e_map[s] if s in e_map else e_map[''])}\n",
    "h_s_map = {'Expired': 0, 'Alive': 1, '': 2, 'NaN': 2}\n",
    "def transform_hospital_discharge_status(status_series):\n",
    "    global h_s_map\n",
    "    return {'hospitaldischargestatus': status_series.fillna('').apply(\n",
    "        lambda s: h_s_map[s] if s in h_s_map else h_s_map[''])}\n",
    "def transform_unit_discharge_status(status_series):\n",
    "    global h_s_map\n",
    "    return {'unitdischargestatus': status_series.fillna('').apply(\n",
    "        lambda s: h_s_map[s] if s in h_s_map else h_s_map[''])}\n",
    "def transform_dx_into_id(df):\n",
    "    dx_type = df.apacheadmissiondx.unique()\n",
    "    dict_dx_key = pd.factorize(dx_type)[1]\n",
    "    dict_dx_val = pd.factorize(dx_type)[0]\n",
    "    dictionary = dict(zip(dict_dx_key, dict_dx_val))\n",
    "    df['apacheadmissiondx'] = df['apacheadmissiondx'].map(dictionary)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patients_table(eicu_path, root_path):\n",
    "    pats = dataframe_from_csv(os.path.join(eicu_path, 'patient.csv'),index_col=False)\n",
    "    pats = filter_patients_on_age(pats, min_age=18, max_age=89)\n",
    "    pats = filter_patients_on_columns(pats)\n",
    "    pats.update(transform_gender(pats.gender))\n",
    "    pats.update(transform_ethnicity(pats.ethnicity))\n",
    "    pats.update(transform_hospital_discharge_status(pats.hospitaldischargestatus))\n",
    "    pats.update(transform_unit_discharge_status(pats.unitdischargestatus))\n",
    "    pats = transform_dx_into_id(pats)\n",
    "    pats.to_csv(os.path.join(root_path, 'all_stays.csv'), index=False)\n",
    "    pats = filter_patients_on_columns_model(pats)\n",
    "    return pats\n",
    "\n",
    "def filter_patients_on_age(patient, min_age=18, max_age=89):\n",
    "    patient.ix[patient['age'] == '> 89','age'] = 90\n",
    "    patient[['age']] = patient[['age']].fillna(-1)\n",
    "    patient[['age']] = patient[['age']].astype(int)\n",
    "    patient = patient.ix[(patient.age >= min_age) & (patient.age <= max_age)]\n",
    "    return patient\n",
    "\n",
    "def filter_patients_on_columns(patients):\n",
    "    columns = ['patientunitstayid','gender', 'age', 'ethnicity','apacheadmissiondx',\n",
    "        'hospitaladmityear',  'hospitaldischargeyear','hospitaldischargeoffset','uniquepid',        \n",
    "        'admissionheight','hospitaladmitoffset', 'admissionweight',\n",
    "        'hospitaldischargestatus','unitdischargeoffset', 'unitdischargestatus']\n",
    "    return patients[columns]\n",
    "def filter_patients_on_columns_model(patients):\n",
    "    columns = ['patientunitstayid','gender', 'age', 'ethnicity','apacheadmissiondx','uniquepid',\n",
    "         'admissionheight','hospitaladmitoffset','admissionweight',\n",
    "         'hospitaldischargestatus','unitdischargeoffset','unitdischargestatus']\n",
    "    return patients[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import os\n",
    "patients = read_patients_table(eicu_path,root_path)\n",
    "patient_cohort = patients[\"patientunitstayid\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.groupby(['uniquepid']).head(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "139367 - 133409"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nurse Charting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = dataframe_from_csv(os.path.join(eicu_path, 'nurseCharting.csv'),index_col=False)\n",
    "ds = nc[nc['nursingchartcelltypevalname']==\"Delirium Score\"].patientunitstayid.unique()\n",
    "cam = nc[nc['nursingchartvalue']==\"CAM-ICU\"].patientunitstayid.unique()\n",
    "cam_cohort = set(ds).intersection(set(cam))\n",
    "cam_cohort = np.array(list(cam_cohort.intersection(set(patient_cohort))))\n",
    "cam_cohort = np.array(cam_cohort)\n",
    "cam_cohort = cam_cohort.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.patientunitstayid.nunique(), cam_cohort.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = nc[nc['patientunitstayid'].isin(cam_cohort)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.to_csv(os.path.join(data_processed_path, 'nc.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_nc_on_columns(nc):\n",
    "    columns =['patientunitstayid','nursingchartoffset','nursingchartcelltypevallabel',\n",
    "              'nursingchartcelltypevalname','nursingchartvalue']\n",
    "    return nc[columns]\n",
    "def rename_nc_columns(nc):\n",
    "    nc.rename(index=str, columns={\"nursingchartoffset\": \"itemoffset\",\n",
    "                                  \"nursingchartcelltypevalname\":\"itemname\",\n",
    "                                  \"nursingchartcelltypevallabel\" : \"itemlabel\",\n",
    "                                  \"nursingchartvalue\": \"itemvalue\"}, inplace=True)\n",
    "    return nc\n",
    "def item_name_selected_from_nc(nc,label,name):\n",
    "    nc = nc[(nc.itemname.isin(name)) & (nc.itemlabel.isin(label))]\n",
    "    return nc\n",
    "def unify_itemname_nc(nc):  #SYNC\n",
    "    nc.loc[nc['itemname']=='Value','itemname'] = nc.itemlabel\n",
    "    nc.loc[nc['itemname']=='Non-Invasive BP Systolic','itemname'] = 'BP Systolic'\n",
    "    nc.loc[nc['itemname']=='Non-Invasive BP Diastolic','itemname'] = 'BP Diastolic'\n",
    "    nc.loc[nc['itemname']=='Invasive BP Systolic','itemname'] = 'BP Systolic'\n",
    "    nc.loc[nc['itemname']=='Invasive BP Diastolic','itemname'] = 'BP Diastolic'\n",
    "    nc.loc[nc['itemlabel']=='Arterial Line MAP (mmHg)','itemname'] = 'MAP (mmHg)'\n",
    "    nc.loc[nc['itemlabel']=='Invasive BP Mean','itemname'] = 'MAP (mmHg)'\n",
    "    nc.loc[nc['itemlabel']=='Non-Invasive BP Mean','itemname'] = 'MAP (mmHg)'\n",
    "    nc.loc[nc['itemlabel']=='SpO2','itemname'] = 'O2 Saturation'\n",
    "    nc.loc[nc['itemlabel']=='Bedside Glucose','itemname'] = 'glucose'\n",
    "    return nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nc_table(data_processed_path):    #SYNC\n",
    "    nc = dataframe_from_csv(os.path.join(data_processed_path, 'nc.csv'),index_col=False)\n",
    "    nc = filter_nc_on_columns(nc)\n",
    "    nc = rename_nc_columns(nc)\n",
    "      vitals = [['O2 Saturation' ,'O2 Saturation'],\n",
    "          ['SpO2', 'Value'],\n",
    "          ['Heart Rate' ,'Heart Rate'],\n",
    "          ['Temperature' ,'Temperature (C)'],\n",
    "          ['Bedside Glucose' ,'Bedside Glucose'],\n",
    "          ['Delirium Scale/Score' ,'Delirium Score'],\n",
    "          ['Glasgow coma score' ,'Verbal'],\n",
    "          ['Glasgow coma score' ,'GCS Total'],\n",
    "          ['Glasgow coma score' ,'Eyes'],\n",
    "          ['Glasgow coma score' ,'Motor'],\n",
    "          ['Glasgow coma score' ,'Verbal'],\n",
    "          ['Non-Invasive BP' ,'Non-Invasive BP Systolic'],\n",
    "          ['Non-Invasive BP' ,'Non-Invasive BP Diastolic'],\n",
    "          ['Invasive BP' ,'Invasive BP Systolic'],\n",
    "          ['Invasive BP' ,'Invasive BP Diastolic'],\n",
    "          ['MAP (mmHg)' ,'Value'],\n",
    "          ['Sedation Scale/Score/Goal','Sedation Score'],\n",
    "          ['ICP', 'ICP'],\n",
    "          ['CI','CI'],\n",
    "          ['Respiratory Rate','Respiratory Rate']] \n",
    "\n",
    "    label , name = [],[]\n",
    "    for v in vitals:\n",
    "        label.append(v[0])\n",
    "        name.append(v[1])\n",
    "    nc = item_name_selected_from_nc(nc,label,name)\n",
    "    nc = unify_itemname_nc(nc)\n",
    "    del nc['itemlabel']\n",
    "    return nc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = read_nc_table(data_processed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_items = nc.itemname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_up_stays_by_unit_stay_nc(nursecharting, root_path, stayid=None, verbose=1):\n",
    "    unit_stays = nursecharting.patientunitstayid.unique() if stayid is None else stayid\n",
    "    nb_unit_stays = unit_stays.shape[0]\n",
    "    for i, stay_id in enumerate(unit_stays):\n",
    "        if verbose:\n",
    "            sys.stdout.write('\\rStayID {0} of {1}...'.format(i+1, nb_unit_stays))\n",
    "        dn = os.path.join(root_path, str(stay_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "        nursecharting.ix[nursecharting.patientunitstayid == stay_id].sort_values(by='itemoffset').to_csv(os.path.join(dn, 'nc.csv'), index=False)\n",
    "    if verbose:\n",
    "        sys.stdout.write('DONE!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24628"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cam_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_up_stays_by_unit_stay_nc(nc,root_path,stayid=cam_cohort, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_up_stays_by_unit_stay(pats, root_path, stayid=None, verbose=1):\n",
    "    unit_stays = pats.patientunitstayid.unique() if stayid is None else stayid\n",
    "    nb_unit_stays = unit_stays.shape[0]\n",
    "    for i, stay_id in enumerate(unit_stays):\n",
    "        if verbose:\n",
    "            sys.stdout.write('\\rStayID {0} of {1}...'.format(i+1, nb_unit_stays))\n",
    "        dn = os.path.join(root_path, str(stay_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "        pat = pats.loc[pats[\"patientunitstayid\"] == stay_id]\n",
    "        pat.to_csv(os.path.join(dn, 'pat.csv'), index=False)\n",
    "    if verbose:\n",
    "        sys.stdout.write('DONE!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_up_stays_by_unit_stay(patients, root_path,stayid=cam_cohort, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similiar Lab items, NC items and InfDrg items need to be unified "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = dataframe_from_csv(os.path.join(eicu_path, 'lab.csv'),index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lab_on_columns(lab):\n",
    "    columns = ['patientunitstayid','labresultoffset', 'labname', 'labresult']\n",
    "    return lab[columns]\n",
    "\n",
    "def rename_lab_columns(lab):\n",
    "    lab.rename(index=str, columns={\"labresultoffset\": \"itemoffset\",\n",
    "                                   \"labname\": \"itemname\", \"labresult\": \"itemvalue\"}, inplace=True)\n",
    "    return lab\n",
    "\n",
    "def item_name_selected_from_lab(lab,items):\n",
    "    lab= lab[lab['itemname'].isin(items)]\n",
    "    return lab\n",
    "\n",
    "def check(x):\n",
    "    try:\n",
    "        x = float(str(x).strip())\n",
    "    except:\n",
    "        x = np.nan\n",
    "    return x\n",
    "\n",
    "def check_itemvalue(df):\n",
    "    df['itemvalue'] = df['itemvalue'].apply(lambda x: check(x))\n",
    "    df['itemvalue'] = df['itemvalue'].astype(float)\n",
    "    return df\n",
    "\n",
    "def read_lab_table(eicu_path):\n",
    "    lab = dataframe_from_csv(os.path.join(eicu_path, 'lab.csv'),index_col=False)\n",
    "    \n",
    "    items = ['O2 Sat (%)','WBC x 1000','sodium','BUN',\n",
    "             'bedside glucose','glucose', \n",
    "             'direct bilirubin',\n",
    "             'Hgb','platelets x 1000','potassium','chloride','bicarbonate',\n",
    "             'creatinine','ALT (SGPT)','AST (SGOT)','alkaline phos.',\n",
    "             'lactate','pH','ammonia','cortisol','TSH','serum osmolality']\n",
    "\n",
    "    lab = filter_lab_on_columns(lab)  \n",
    "    lab = rename_lab_columns(lab)\n",
    "    lab = item_name_selected_from_lab(lab,items) \n",
    "    lab.loc[lab['itemname'] == 'bedside glucose', 'itemname'] = 'glucose'  \n",
    "    lab.loc[lab['itemname'] == 'O2 Sat (%)', 'itemname'] = 'O2 Saturation'\n",
    "    lab = check_itemvalue(lab)\n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = read_lab_table(eicu_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_up_lab_by_unit_stay(lab, root_path, stayid=None, verbose=1):\n",
    "    unit_stays = lab.patientunitstayid.unique() if stayid is None else stayid\n",
    "    nb_unit_stays = unit_stays.shape[0]\n",
    "    for i, stay_id in enumerate(unit_stays):\n",
    "        if verbose:\n",
    "            sys.stdout.write('\\rStayID {0} of {1}...'.format(i+1, nb_unit_stays))\n",
    "        dn = os.path.join(root_path, str(stay_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "        lab.ix[lab.patientunitstayid == stay_id].sort_values(by='itemoffset').to_csv(os.path.join(dn, 'lab.csv'), index=False)\n",
    "    if verbose:\n",
    "        sys.stdout.write('DONE!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_items = lab.itemname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_up_lab_by_unit_stay(lab,root_path,stayid = cam_cohort, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read each patient nc, lab and demographics and put all in one csv file named as time_series{ID}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_events_to_timeseries(events, variable_column='itemname', variables=[]):\n",
    "    metadata = events[['itemoffset', 'patientunitstayid']].sort_values(by=['itemoffset', 'patientunitstayid'])\\\n",
    "                    .drop_duplicates(keep='first').set_index('itemoffset')\n",
    "    timeseries = events[['itemoffset', variable_column, 'itemvalue']]\\\n",
    "                    .sort_values(by=['itemoffset', variable_column, 'itemvalue'], axis=0)\\\n",
    "                    .drop_duplicates(subset=['itemoffset', variable_column], keep='last')\n",
    "    timeseries = timeseries.pivot(index='itemoffset', columns=variable_column, values='itemvalue').merge(metadata, left_index=True, right_index=True)\\\n",
    "                    .sort_index(axis=0).reset_index()\n",
    "    for v in variables:\n",
    "        if v not in timeseries:\n",
    "            timeseries[v] = np.nan\n",
    "    return timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lab_items), len(nc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_consider = list(lab_items) + list(nc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(var_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(df, x=60):\n",
    "    df['itemoffset'] = (df['itemoffset']/x).astype(int)\n",
    "    df = df.groupby('itemoffset').apply(lambda x: x.fillna(x.mean()))\n",
    "    df = df.droplevel(0,axis=0)\n",
    "    df.drop_duplicates(subset=['itemoffset'], keep='last',inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_series_from_subject(t_path):\n",
    "    for stay_dir in os.listdir(t_path):\n",
    "        dn = os.path.join(t_path, stay_dir)\n",
    "        try:\n",
    "            stay_id = int(stay_dir)\n",
    "            if not os.path.isdir(dn):\n",
    "                raise Exception\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            pat = dataframe_from_csv(os.path.join(t_path, stay_dir, 'pat.csv'))\n",
    "            lab = dataframe_from_csv(os.path.join(t_path, stay_dir, 'lab.csv'))\n",
    "            nc = dataframe_from_csv(os.path.join(t_path, stay_dir, 'nc.csv'))\n",
    "            nclab = pd.concat([nc, lab]).sort_values(by=['itemoffset'])\n",
    "            timeepisode = convert_events_to_timeseries(nclab, variables=var_to_consider)\n",
    "            nclabpat = pd.merge(timeepisode, pat, on='patientunitstayid')\n",
    "            df = binning(nclabpat, 60)\n",
    "            df.to_csv(os.path.join(t_path, stay_dir, 'timeseries.csv'), index=False)\n",
    "            sys.stdout.write('\\rWrite StayID {0}...'.format(stay_id))\n",
    "        except:\n",
    "            continue\n",
    "    print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_time_series_from_subject(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete folders without timeseries file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def delete_wo_timeseries(t_path):\n",
    "    for stay_dir in os.listdir(t_path):\n",
    "        dn = os.path.join(t_path, stay_dir)\n",
    "        try:\n",
    "            stay_id = int(stay_dir)\n",
    "            if not os.path.isdir(dn):\n",
    "                raise Exception\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            sys.stdout.flush()\n",
    "            if not os.path.isfile(os.path.join(dn,'timeseries.csv')):\n",
    "                shutil.rmtree(dn)   \n",
    "        except :\n",
    "            continue\n",
    "    print('DONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "delete_wo_timeseries(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the data in one dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "unit_stays  = pd.Series(os.listdir(root_path))\n",
    "unit_stays = list((filter(str.isdigit, unit_stays)))\n",
    "\n",
    "all_filenames = []\n",
    "for stay_id in(unit_stays):\n",
    "    df_file = os.path.join(root_path, str(stay_id),'timeseries.csv')\n",
    "    all_filenames.append(df_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n",
    "combined_csv.to_csv(os.path.join(data_processed_path, 'all_data_delirium_eicu.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = read_patients_table(eicu_path,root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_ = patients[['patientunitstayid','uniquepid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_deli = pd.read_csv(os.path.join(data_processed_path, 'all_data_delirium_eicu.csv'))\n",
    "all_data_deli.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_deli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_deli = pd.merge(all_data_deli, patients_, how='left', left_on=['patientunitstayid'],right_on=['patientunitstayid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_deli.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_deli[\"Delirium Score\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_deli[\"Delirium Score\"] = all_data_deli[\"Delirium Score\"].str.lower()\n",
    "df = all_data_deli[(all_data_deli[\"Delirium Score\"]=='yes')|(all_data_deli[\"Delirium Score\"]=='no')|(all_data_deli[\"Delirium Score\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Delirium Score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index=str, columns={\"Hgb\": \"Hemoglobin\",\n",
    "                                         \"platelets x 1000\": \"Platelets\",\n",
    "                                          \"potassium\":\"Potassium\",\n",
    "                                          \"chloride\" : \"Chloride\",\n",
    "                                          \"bicarbonate\": \"Bicarbonate\",\n",
    "                                          \"creatinine\": \"Creatinine\",\n",
    "                                          \"ALT (SGPT)\": \"ALT\",\n",
    "                                          \"AST (SGOT)\": \"AST\",\n",
    "                                          \"alkaline phos.\": \"Alkaline Phosphate\",\n",
    "                                          \"Delirium Score\": \"CAM\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"patientunitstayid\").count().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"uniquepid\").count().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add sofa score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eicu = df.copy()\n",
    "sofa = pd.read_csv(os.path.join(data_processed_path, 'eicu_pivoted_sofa.csv'))\n",
    "\n",
    "df_eicu['day'] = np.nan\n",
    "\n",
    "for i in range(1,1000):\n",
    "    df_eicu.loc[((df_eicu['itemoffset'] <= i*24) & (df_eicu['itemoffset'] >= (i-1)*24)),'day'] = i\n",
    "    \n",
    "new_df = pd.merge(df_eicu, sofa, how='left', left_on=['patientunitstayid','day'],right_on=['patientunitstayid','day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = ['patientunitstayid','uniquepid', 'itemoffset', 'gender', 'age', 'admissionheight',\n",
    "       'admissionweight', 'Heart Rate', 'O2 Saturation', 'glucose',\n",
    "       'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'direct bilirubin',\n",
    "       'Hemoglobin', 'Platelets', 'Potassium', 'Chloride', 'Bicarbonate',\n",
    "       'Creatinine', 'ALT', 'AST', 'Alkaline Phosphate','sofa', 'sofa_wo_gcs','CAM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_map = {'no': 0, 'yes': 1,'':2}\n",
    "\n",
    "def transform_deli(deli_series):\n",
    "    global d_map\n",
    "    return {'CAM': deli_series.fillna('').apply(lambda s: d_map[s] if s in d_map else d_map[''])}\n",
    "\n",
    "new_df.update(transform_deli(new_df['CAM']))\n",
    "new_df [\"CAM\"] = new_df[\"CAM\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eicu = new_df.copy()\n",
    "df_vent = pd.read_csv(os.path.join(data_processed_path, 'eicu_wes.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(df_eicu, df_vent, how='left', left_on=['patientunitstayid','itemoffset'],right_on=['patientunitstayid','hr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deli = new_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = ['patientunitstayid','uniquepid', 'itemoffset', 'gender', 'age', 'admissionheight',\n",
    "       'admissionweight', 'Heart Rate', 'O2 Saturation', 'glucose',\n",
    "       'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'direct bilirubin',\n",
    "       'Hemoglobin', 'Platelets', 'Potassium', 'Chloride', 'Bicarbonate',\n",
    "       'Creatinine', 'ALT', 'AST', 'Alkaline Phosphate', 'sofa', 'sofa_wo_gcs',\n",
    "       'vent_flag','rate_dopamine', 'rate_epinephrine', 'rate_norepinephrine',\n",
    "       'rate_phenylephrine', 'fluidin', 'fluidout','CAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deli = all_deli[columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_deli = all_deli[all_deli['itemoffset'] > -7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_deli = all_deli.copy()\n",
    "label_deli['labelrec'] = np.nan\n",
    "label_deli.loc[label_deli['CAM']==1,'labelrec']=1\n",
    "label_deli.loc[label_deli['CAM']==0,'labelrec']=0\n",
    "\n",
    "label_deli['labelpt'] = np.nan\n",
    "\n",
    "pos_cam_coh = label_deli[label_deli['labelrec']==1]['patientunitstayid'].unique()\n",
    "label_deli.loc[label_deli['patientunitstayid'].isin(pos_cam_coh), 'labelpt']=1\n",
    "label_deli.loc[~(label_deli['patientunitstayid'].isin(pos_cam_coh)), 'labelpt']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = ['patientunitstayid','uniquepid', 'itemoffset', 'gender', 'age', 'admissionheight',\n",
    "       'admissionweight', 'Heart Rate', 'O2 Saturation', 'glucose',\n",
    "       'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'direct bilirubin',\n",
    "       'Hemoglobin', 'Platelets', 'Potassium', 'Chloride', 'Bicarbonate',\n",
    "       'Creatinine', 'ALT', 'AST', 'Alkaline Phosphate', 'sofa', 'sofa_wo_gcs',\n",
    "       'vent_flag','rate_dopamine', 'rate_epinephrine', 'rate_norepinephrine',\n",
    "       'rate_phenylephrine', 'fluidin', 'fluidout','CAM','labelrec','labelpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_deli = label_deli[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patientunitstayid', 'uniquepid', 'itemoffset', 'gender', 'age',\n",
       "       'admissionheight', 'admissionweight', 'Heart Rate', 'O2 Saturation',\n",
       "       'glucose', 'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000',\n",
       "       'direct bilirubin', 'Hemoglobin', 'Platelets', 'Potassium', 'Chloride',\n",
       "       'Bicarbonate', 'Creatinine', 'ALT', 'AST', 'Alkaline Phosphate', 'sofa',\n",
       "       'sofa_wo_gcs', 'vent_flag', 'rate_dopamine', 'rate_epinephrine',\n",
       "       'rate_norepinephrine', 'rate_phenylephrine', 'fluidin', 'fluidout',\n",
       "       'CAM', 'labelrec', 'labelpt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_deli.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = label_deli.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "columns = columns_order \n",
    "percent_missing = new_df[columns].isnull().sum() * 100 / len(new_df)\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df.reset_index(inplace=True, drop=True)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient-wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = new_df[columns_order].groupby(\"patientunitstayid\").apply(lambda x: x.notnull().mean())\n",
    "\n",
    "for i in df_g.columns:\n",
    "    df_g[i] = df_g[i].replace({0:np.nan})\n",
    "\n",
    "    \n",
    "    #after Imputation\n",
    "\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "columns = df_g.columns\n",
    "percent_missing = df_g.isnull().sum() * 100 / len(df_g)\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df.reset_index(inplace=True, drop=True)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_corr = ['Age', 'Height',\n",
    "       'Weight', 'Heart Rate', 'O2 Saturation', 'Glucose',\n",
    "       'Temperature', 'Sodium', 'BUN', 'WBC', \n",
    "       'Hemoglobin', 'Platelets', 'Potassium', 'Chloride', 'Bicarbonate',\n",
    "       'Creatinine','Ventilation','Vasopressor dose','Gender','Sofa', 'Sofa_wo_gcs',  'CAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rename(index=str, columns={\"admissionheight\": \"Height\",\n",
    "                                  \"admissionweight\":\"Weight\",\n",
    "                                  \"glucose\" : \"Glucose\",\n",
    "                                  \"sodium\" : \"Sodium\",\n",
    "                                  \"vent_flag\" : \"Ventilation\",\n",
    "                                  \"rate_dopamine\" : \"Dopamine\",\n",
    "                                  \"rate_epinephrine\" : \"Epinephrine\",\n",
    "                                  \"rate_norepinephrine\":\"Norepinephrine\",\n",
    "                                  \"rate_phenylephrine\":\"Phenylephrine\",\n",
    "                                  \"gender\":\"Gender\",\n",
    "                                  \"sofa\":\"Sofa\",\n",
    "                                  \"sofa_wo_gcs\":\"Sofa_wo_gcs\",\n",
    "                                  \"Temperature (C)\" : \"Temperature\",\n",
    "                                  \"WBC x 1000\": \"WBC\",\n",
    "                                  \"age\":\"Age\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Epinephrine'].fillna(value=0,inplace=True)\n",
    "new_df['Norepinephrine'].fillna(value=0,inplace=True) \n",
    "new_df['Phenylephrine'].fillna(value=0,inplace=True)\n",
    "new_df['Dopamine'].fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Epinephrine'].fillna(value=0,inplace=True)\n",
    "new_df['Norepinephrine'].fillna(value=0,inplace=True) \n",
    "new_df['Phenylephrine'].fillna(value=0,inplace=True)\n",
    "new_df['Dopamine'].fillna(value=0,inplace=True)\n",
    "new_df['Vasopressor dose'] = np.nan\n",
    "new_df['Vasopressor dose'] = new_df['Epinephrine']+new_df['Norepinephrine'] + new_df['Phenylephrine']/10 + new_df['Dopamine']/2\n",
    "new_df.drop(columns=['Epinephrine', 'Norepinephrine','Phenylephrine','Dopamine'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_corr = ['Age', 'Height',\n",
    "       'Weight', 'Heart Rate', 'O2 Saturation', 'Glucose',\n",
    "       'Temperature', 'Sodium', 'BUN', 'WBC', \n",
    "       'Hemoglobin', 'Platelets', 'Potassium', 'Chloride', 'Bicarbonate',\n",
    "       'Creatinine','Ventilation','Vasopressor dose','Gender','Sofa', 'Sofa_wo_gcs',  'CAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colormap = plt.cm.RdBu\n",
    "\n",
    "mask = np.zeros(new_df[columns_for_corr].corr().shape, dtype=bool)\n",
    "mask[np.tril_indices(len(mask))] = True\n",
    "mask = ~mask\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "sns.heatmap(new_df[columns_for_corr].corr(), mask = mask, linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=False)\n",
    "\n",
    "plt.savefig('eicu_corr_jama.png',dpi=450, facecolor='white', bbox_inches = 'tight',transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x):\n",
    "    try:\n",
    "        x = float(str(x).strip())\n",
    "    except:\n",
    "        x = np.nan\n",
    "    return x\n",
    "\n",
    "def check_itemvalue(df):\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].apply(lambda x: check(x))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patientunitstayid', 'uniquepid', 'itemoffset', 'Gender', 'Age',\n",
       "       'Height', 'Weight', 'Heart Rate', 'O2 Saturation', 'Glucose',\n",
       "       'Temperature', 'Sodium', 'BUN', 'WBC', 'direct bilirubin', 'Hemoglobin',\n",
       "       'Platelets', 'Potassium', 'Chloride', 'Bicarbonate', 'Creatinine',\n",
       "       'ALT', 'AST', 'Alkaline Phosphate', 'Sofa', 'Sofa_wo_gcs',\n",
       "       'Ventilation', 'fluidin', 'fluidout', 'CAM', 'labelrec', 'labelpt',\n",
       "       'Vasopressor dose'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_columns = ['Age', 'Height','Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean Imputation of each patient\n",
    "for i in mean_columns:\n",
    "    new_df[i].fillna(new_df.groupby(\"patientunitstayid\")[i].transform('mean'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute with mean of whole cohort\n",
    "for i in mean_columns:\n",
    "    new_df[i] = new_df[i].fillna(new_df[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No. of Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.groupby(\"patientunitstayid\").count().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.groupby(\"uniquepid\").count().shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save not imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "los = pd.read_csv(os.path.join(eicu_path, 'apachePatientResult.csv'))\n",
    "los = los[['patientunitstayid','actualiculos']]\n",
    "los['actualiculos'] = los['actualiculos'] * 24\n",
    "los.rename(columns={\"actualiculos\": \"LOS\"},inplace=True)\n",
    "new_df_los = pd.merge(new_df, los, how='left', left_on=['patientunitstayid'],right_on=['patientunitstayid'])\n",
    "new_df_los = new_df_los[new_df_los['LOS']>=24]       \n",
    "new_df_los = new_df_los[new_df_los['itemoffset'] > 0] #CHANGE TO ZERO\n",
    "new_df_los_nodups = new_df_los.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_deli = new_df_los_nodups.copy()\n",
    "label_deli['labelrec'] = np.nan\n",
    "label_deli.loc[label_deli['CAM']==1,'labelrec']=1\n",
    "label_deli.loc[label_deli['CAM']==0,'labelrec']=0\n",
    "label_deli['labelpt'] = np.nan\n",
    "pos_cam_coh = label_deli[label_deli['labelrec']==1]['patientunitstayid'].unique()\n",
    "label_deli.loc[label_deli['patientunitstayid'].isin(pos_cam_coh), 'labelpt']=1\n",
    "label_deli.loc[~(label_deli['patientunitstayid'].isin(pos_cam_coh)), 'labelpt']=0\n",
    "pos_cam_df = label_deli[label_deli['labelpt']==1]\n",
    "neg_cam_df = label_deli[label_deli['labelpt']==0]\n",
    "pos_cam_df.reset_index(inplace=True)\n",
    "pos_cam_df = pos_cam_df.drop(columns=['index'])\n",
    "neg_cam_df.reset_index(inplace=True)\n",
    "neg_cam_df = neg_cam_df.drop(columns=['index'])\n",
    "neg_cam_df['CAM'] = neg_cam_df['labelpt']\n",
    "pos_cam_df['CAM'] = pos_cam_df['labelpt']\n",
    "pos_cam_df.to_csv(os.path.join(data_processed_path, 'pos_eicu_notimputed_24los.csv'), index=False)\n",
    "neg_cam_df.to_csv(os.path.join(data_processed_path, 'neg_eicu_notimputed_24los.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16546, 33)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_los_nodups.groupby(\"patientunitstayid\").count().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14228, 33)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_los_nodups.groupby(\"uniquepid\").count().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_columns = ['vent_flag', 'rate_dopamine', 'rate_epinephrine', 'rate_norepinephrine',\n",
    "       'rate_phenylephrine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[zero_columns] = new_df[zero_columns].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PATIENT WISE ZERO FILL\n",
    "\n",
    "df_g = new_df[columns_order].groupby(\"patientunitstayid\").apply(lambda x: x.notnull().mean())\n",
    "\n",
    "for i in df_g.columns:\n",
    "    df_g[i] = df_g[i].replace({0:np.nan})\n",
    "\n",
    "    \n",
    "    #after Imputation\n",
    "\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "columns = df_g.columns\n",
    "percent_missing = df_g.isnull().sum() * 100 / len(df_g)\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df.reset_index(inplace=True, drop=True)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_columns = ['Heart Rate', 'O2 Saturation', 'glucose',\n",
    "       'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'direct bilirubin',\n",
    "       'Hemoglobin', 'Platelets', 'Potassium', 'Chloride', 'Bicarbonate',\n",
    "       'Creatinine', 'ALT', 'AST', 'Alkaline Phosphate', 'sofa', 'sofa_wo_gcs','fluidin', 'fluidout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in forward_columns:\n",
    "    new_df[i] = new_df.groupby(\"patientunitstayid\")[i].transform(lambda v: v.ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PATIENT WISE FORWARD FILL\n",
    "\n",
    "df_g = new_df[columns_order].groupby(\"patientunitstayid\").apply(lambda x: x.notnull().mean())\n",
    "\n",
    "for i in df_g.columns:\n",
    "    df_g[i] = df_g[i].replace({0:np.nan})\n",
    "\n",
    "    \n",
    "    #after Imputation\n",
    "\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "columns = df_g.columns\n",
    "percent_missing = df_g.isnull().sum() * 100 / len(df_g)\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df.reset_index(inplace=True, drop=True)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_columns = forward_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in backward_columns:\n",
    "    new_df[i] = new_df.groupby(\"patientunitstayid\")[i].transform(lambda v: v.bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.patientunitstayid.nunique(), new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOS at least 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "los = pd.read_csv(os.path.join(eicu_path, 'apachePatientResult.csv'))\n",
    "los = los[['patientunitstayid','actualiculos']]\n",
    "los['actualiculos'] = los['actualiculos'] * 24\n",
    "los.rename(columns={\"actualiculos\": \"LOS\"},inplace=True)\n",
    "new_df_los = pd.merge(new_df, los, how='left', left_on=['patientunitstayid'],right_on=['patientunitstayid'])\n",
    "new_df_los = new_df_los[new_df_los['LOS']>=24]\n",
    "new_df_los = new_df_los[new_df_los['itemoffset'] > 0] #CHANGE TO ZERO\n",
    "new_df_los_nodups = new_df_los.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_los_nodups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_los_nodups.groupby(\"patientunitstayid\").count().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISSING RATE After Filtering on 48 hours\n",
    "df_g = new_df_los_nodups[columns_order].groupby(\"patientunitstayid\").apply(lambda x: x.notnull().mean())\n",
    "for i in df_g.columns:\n",
    "    df_g[i] = df_g[i].replace({0:np.nan})\n",
    "    #after Imputation\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "columns = df_g.columns\n",
    "percent_missing = df_g.isnull().sum() * 100 / len(df_g)\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df.reset_index(inplace=True, drop=True)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MISSING RATE After Filtering on 48 hours\n",
    "\n",
    "\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "columns = columns_order \n",
    "percent_missing = new_df_los_nodups[columns].isnull().sum() * 100 / len(new_df_los_nodups)\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "missing_value_df.reset_index(inplace=True, drop=True)\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns with high missing rate (ALT,AST,Alk Ph, Dir Bil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df_los_nodups.patientunitstayid.nunique(), new_df_los_nodups.shape)\n",
    "\n",
    "new_df_los_nodups.drop(columns=['ALT', 'AST','Alkaline Phosphate','direct bilirubin','fluidin', 'fluidout'],inplace=True)\n",
    "\n",
    "print(new_df_los_nodups.patientunitstayid.nunique())\n",
    "\n",
    "print(new_df_los_nodups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df_los_nodups.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values dropna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order = ['patientunitstayid', 'itemoffset', 'gender', 'age', 'admissionheight',\n",
    "       'admissionweight', 'Heart Rate', 'O2 Saturation', 'glucose',\n",
    "       'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'Hemoglobin',\n",
    "        'Platelets', 'Potassium', 'Chloride', 'Bicarbonate',\n",
    "       'Creatinine', 'sofa', 'sofa_wo_gcs',\n",
    "       'vent_flag','rate_dopamine', 'rate_epinephrine', 'rate_norepinephrine',\n",
    "       'rate_phenylephrine','LOS','CAM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop patients with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_los_nodups.dropna(subset=['Heart Rate', 'O2 Saturation', 'glucose',\n",
    "       'Temperature (C)', 'sodium', 'BUN', 'WBC x 1000', 'Hemoglobin',\n",
    "       'Platelets', 'Potassium', 'Chloride', 'Bicarbonate', 'Creatinine',\n",
    "       'sofa', 'sofa_wo_gcs', 'vent_flag', 'rate_dopamine', 'rate_epinephrine',\n",
    "       'rate_norepinephrine', 'rate_phenylephrine'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_deli = new_df_los_nodups.copy()\n",
    "label_deli['labelrec'] = np.nan\n",
    "label_deli.loc[label_deli['CAM']==1,'labelrec']=1\n",
    "label_deli.loc[label_deli['CAM']==0,'labelrec']=0\n",
    "label_deli['labelpt'] = np.nan\n",
    "\n",
    "\n",
    "pos_cam_coh = label_deli[label_deli['labelrec']==1]['patientunitstayid'].unique()\n",
    "label_deli.loc[label_deli['patientunitstayid'].isin(pos_cam_coh), 'labelpt']=1\n",
    "label_deli.loc[~(label_deli['patientunitstayid'].isin(pos_cam_coh)), 'labelpt']=0\n",
    "\n",
    "\n",
    "pos_cam_df = label_deli[label_deli['labelpt']==1]\n",
    "neg_cam_df = label_deli[label_deli['labelpt']==0]\n",
    "pos_cam_df.reset_index(inplace=True)\n",
    "pos_cam_df = pos_cam_df.drop(columns=['index'])\n",
    "\n",
    "neg_cam_df.reset_index(inplace=True)\n",
    "neg_cam_df = neg_cam_df.drop(columns=['index'])\n",
    "\n",
    "neg_cam_df['CAM'] = neg_cam_df['labelpt']\n",
    "pos_cam_df['CAM'] = pos_cam_df['labelpt']\n",
    "\n",
    "pos_cam_df.to_csv(os.path.join(data_processed_path, 'pos_eicu_imputed_24los.csv'), index=False)\n",
    "neg_cam_df.to_csv(os.path.join(data_processed_path, 'neg_eicu_imputed_24los.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cam_df.to_csv(os.path.join(data_processed_path, 'pos_eicu_imputed_24los.csv'), index=False)\n",
    "neg_cam_df.to_csv(os.path.join(data_processed_path, 'neg_eicu_imputed_24los.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cam_df['patientunitstayid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_cam_df['patientunitstayid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "eicu_df = pd.concat([neg_cam_df, pos_cam_df],axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
